---
layout: Post
title: gRPC
subtitle:
author: Alomerry Wu
date: 2022-02-26
headerImage: https://cdn.alomerry.com/blog/img/in-post/header-image?max=29
catalog: true
tags:
- Y2022
- golang
---

## gRPC

http://www.likecs.com/show-124458.html

## 1.26

### gRPC 服务注册发现及负载均衡的实现方案与源码解析

https://blog.csdn.net/kevin_tech/article/details/109281835

### RoundRobin

grpc client 端创建连接时可以用 WithBalancer 来指定负载均衡组件，这里研究下 grpc 自带的 RoundRobin（轮询调度）的实现。源码在 google.golang.org/grpc/balancer.go 中。

roundRobin 结构体定义如下：

```
type roundRobin struct {
	r      naming.Resolver
	w      naming.Watcher
	addrs  []*addrInfo
	mu     sync.Mutex
	addrCh chan []Address
	next   int
	waitCh chan struct{}
	done   bool
}
```

- r 是命名解析器，可以定义自己的命名解析器，如 etcd 命名解析器。如果 r 为 nil，那么 Dial 中参数 target 将直接作为可请求地址添加到 addrs 中。
- w 是命名解析器 Resolve 方法返回的 watcher，该 watcher 可以监听命名解析器发来的地址信息变化，通知 roundRobin 对 addrs 中的地址进行动态的增删。
- addrs 是从命名解析器获取地址信息数组，数组中每个地址不仅有地址信息，还有 grpc 与该地址是否已经创建了 ready 状态的连接。
- addrCh 是地址数组的 channel，该 channel 会在每次命名解析器发来地址信息变化后，将所有 addrs 通知到 grpc 内部的 lbWatcher，lbWatcher 是统一管理地址连接状态的协程，负责新地址的连接与被删除地址的关闭操作。
- next 是 roundRobin 的 Index，即轮询调度遍历到 addrs 数组中的哪个位置了。
- waitCh 是当 addrs 中地址为空时，grpc 调用 Get()方法希望获取到一个到 target 的连接，如果设置了 grpc 的 failfast 为 false，那么 Get()方法会阻塞在此 channel 上，直到有 ready 的连接。

#### roundRobin 启动

```go
func (rr *roundRobin) Start(target string, config BalancerConfig) error {
	rr.mu.Lock()
	defer rr.mu.Unlock()
	if rr.done {
		return ErrClientConnClosing
	}
	if rr.r == nil {
		// 如果没有解析器，那么直接将target加入addrs地址数组
		rr.addrs = append(rr.addrs, &addrInfo{addr: Address{Addr: target}})
		return nil
	}
	// Resolve接口会返回一个watcher，watcher可以监听解析器的地址变化
	w, err := rr.r.Resolve(target)
	if err != nil {
		return err
	}
	rr.w = w
	// 创建一个channel，当watcher监听到地址变化时，通知grpc内部lbWatcher去连接该地址
	rr.addrCh = make(chan []Address, 1)
	// go 出去监听watcher，监听地址变化。
	go func() {
		for {
			if err := rr.watchAddrUpdates(); err != nil {
				return
			}
		}
	}()
	return nil
}
```

#### 监听命名解析器的地址变化：

```go
func (rr *roundRobin) watchAddrUpdates() error {
	// watcher的next方法会阻塞，直至有地址变化信息过来，updates即为变化信息
	updates, err := rr.w.Next()
	if err != nil {
		return err
	}
	// 对于addrs地址数组的操作，显然是要加锁的，因为有多个goroutine在同时操作
	rr.mu.Lock()
	defer rr.mu.Unlock()
	for _, update := range updates {
		addr := Address{
			Addr:     update.Addr,
			Metadata: update.Metadata,
		}
		switch update.Op {
		case naming.Add:
		//对于新增类型的地址，注意这里不会重复添加。
			var exist bool
			for _, v := range rr.addrs {
				if addr == v.addr {
					exist = true
					break
				}
			}
			if exist {
				continue
			}
			rr.addrs = append(rr.addrs, &addrInfo{addr: addr})
		case naming.Delete:
		//对于删除的地址，直接在addrs中删除就行了
			for i, v := range rr.addrs {
				if addr == v.addr {
					copy(rr.addrs[i:], rr.addrs[i+1:])
					rr.addrs = rr.addrs[:len(rr.addrs)-1]
					break
				}
			}
		default:
			grpclog.Errorln("Unknown update.Op ", update.Op)
		}
	}
	// 这里复制了整个addrs地址数组，然后丢到addrCh channel中通知grpc内部lbWatcher，
	// lbWatcher会关闭删除的地址，连接新增的地址。
	// 连接ready后会有专门的goroutine调用Up方法修改addrs中地址的状态。
	open := make([]Address, len(rr.addrs))
	for i, v := range rr.addrs {
		open[i] = v.addr
	}
	if rr.done {
		return ErrClientConnClosing
	}
	select {
	case <-rr.addrCh:
	default:
	}
	rr.addrCh <- open
	return nil
}
```

#### Up 方法：

up 方法是 grpc 内部负载均衡 watcher 调用的，该 watcher 会读全局的连接状态改变队列，如果是 ready 状态的连接，会调用 up 方法来改变 addrs 地址数组中该地址的状态为**已连接**。

```go
func (rr *roundRobin) Up(addr Address) func(error) {
	rr.mu.Lock()
	defer rr.mu.Unlock()
	var cnt int
	//将地址数组中的addr置为已连接状态，这样这个地址就可以被client使用了。
	for _, a := range rr.addrs {
		if a.addr == addr {
			if a.connected {
				return nil
			}
			a.connected = true
		}
		if a.connected {
			cnt++
		}
	}
	// 当有一个可用地址时，之前可能是0个，可能要很多client阻塞在获取连接地址上，这里通知所有的client有可用连接啦。
	// 为什么只等于1时通知？因为可用地址数量>1时，client是不会阻塞的。
	if cnt == 1 && rr.waitCh != nil {
		close(rr.waitCh)
		rr.waitCh = nil
	}
	//返回禁用该地址的方法
	return func(err error) {
		rr.down(addr, err)
	}
}
```

#### down 方法：

down 方法就简单了, 直接找到 addr 置为不可用就行了。

```go
//如果addr1已经被连接上了，但是resolver通知删除了，grpc内部如何处理关闭的逻辑？
func (rr *roundRobin) down(addr Address, err error) {
	rr.mu.Lock()
	defer rr.mu.Unlock()
	for _, a := range rr.addrs {
		if addr == a.addr {
			a.connected = false
			break
		}
	}
}
```

#### Get()方法：

client 需要获取一个可用的地址，如果 addrs 为空，或者 addrs 不为空，但是地址都不可用（没连接），Get()方法会返回错误。但是如果设置了 failfast = false，Get()方法会阻塞在 waitCh channel 上，直至 Up 方法给到通知，然后轮询调度可用的地址。

```go
func (rr *roundRobin) Get(ctx context.Context, opts BalancerGetOptions) (addr Address, put func(), err error) {
	var ch chan struct{}
	rr.mu.Lock()
	if rr.done {
		rr.mu.Unlock()
		err = ErrClientConnClosing
		return
	}

	if len(rr.addrs) > 0 {
		// addrs的长度可能变化，如果next值超出了，就置为0，从头开始调度。
		if rr.next >= len(rr.addrs) {
			rr.next = 0
		}
		next := rr.next
		//遍历整个addrs数组，直到选出一个可用的地址
		for {
			a := rr.addrs[next]
			// next值加一，当然是循环的，到len(addrs)后，变为0
			next = (next + 1) % len(rr.addrs)
			if a.connected {
				addr = a.addr
				rr.next = next
				rr.mu.Unlock()
				return
			}
			if next == rr.next {
				// 遍历完一圈了，还没找到，走下面逻辑
				break
			}
		}
	}
	if !opts.BlockingWait { //如果是非阻塞模式，如果没有可用地址，那么报错
		if len(rr.addrs) == 0 {
			rr.mu.Unlock()
			err = status.Errorf(codes.Unavailable, "there is no address available")
			return
		}
		// Returns the next addr on rr.addrs for failfast RPCs.
		addr = rr.addrs[rr.next].addr
		rr.next++
		rr.mu.Unlock()
		return
	}
	// Wait on rr.waitCh for non-failfast RPCs.
	// 如果是阻塞模式，那么需要阻塞在waitCh上，直到Up方法给通知
	if rr.waitCh == nil {
		ch = make(chan struct{})
		rr.waitCh = ch
	} else {
		ch = rr.waitCh
	}
	rr.mu.Unlock()
	for {
		select {
		case <-ctx.Done():
			err = ctx.Err()
			return
		case <-ch:
			rr.mu.Lock()
			if rr.done {
				rr.mu.Unlock()
				err = ErrClientConnClosing
				return
			}

			if len(rr.addrs) > 0 {
				if rr.next >= len(rr.addrs) {
					rr.next = 0
				}
				next := rr.next
				for {
					a := rr.addrs[next]
					next = (next + 1) % len(rr.addrs)
					if a.connected {
						addr = a.addr
						rr.next = next
						rr.mu.Unlock()
						return
					}
					if next == rr.next {
						// 遍历完一圈了，还没找到，可能刚Up的地址被down掉了，重新等待。
						break
					}
				}
			}
			// The newly added addr got removed by Down() again.
			if rr.waitCh == nil {
				ch = make(chan struct{})
				rr.waitCh = ch
			} else {
				ch = rr.waitCh
			}
			rr.mu.Unlock()
		}
	}
}
```

#### lbWatcher：

lbWatcher 会监听地址变化信息，roundroubin 每次有地址变化时，会将所有的地址通知给 lbWatcher，lbWatcher 本身维护了地址连接的 map 表，会找出新添加的地址和需要删除的地址，然后做连接、关闭操作，再调用 roundRobin 的 Up/Down 方法通知连接的状态。

```go
func (bw *balancerWrapper) lbWatcher() {
	notifyCh := bw.balancer.Notify()
	if notifyCh == nil {
		// 没有定义解析器，直接连接这个地址。
		a := resolver.Address{
			Addr: bw.targetAddr,
			Type: resolver.Backend,
		}
		sc, err := bw.cc.NewSubConn([]resolver.Address{a}, balancer.NewSubConnOptions{})
		if err != nil {
			grpclog.Warningf("Error creating connection to %v. Err: %v", a, err)
		} else {
			bw.mu.Lock()
			bw.conns[a] = sc
			bw.connSt[sc] = &scState{
				addr: Address{Addr: bw.targetAddr},
				s:    connectivity.Idle,
			}
			bw.mu.Unlock()
			sc.Connect()
		}
		return
	}

	for addrs := range notifyCh {
			var newAddrs []resolver.Address
			for _, a := range addrs {
				newAddr := resolver.Address{
					Addr:       a.Addr,
					Type:       resolver.Backend, // All addresses from balancer are all backends.
					ServerName: "",
					Metadata:   a.Metadata,
				}
				newAddrs = append(newAddrs, newAddr)
			}
			var (
				add []resolver.Address // Addresses need to setup connections.
				del []balancer.SubConn // Connections need to tear down.
			)
			resAddrs := make(map[resolver.Address]Address)
			for _, a := range addrs {
				resAddrs[resolver.Address{
					Addr:       a.Addr,
					Type:       resolver.Backend, // All addresses from balancer are all backends.
					ServerName: "",
					Metadata:   a.Metadata,
				}] = a
			}
			bw.mu.Lock()
			// 新添加的地址，需要去新建连接
			for a := range resAddrs {
				if _, ok := bw.conns[a]; !ok {
					add = append(add, a)
				}
			}
			// 要被删除的地址，需要去关闭连接
			for a, c := range bw.conns {
				if _, ok := resAddrs[a]; !ok {
					del = append(del, c)
					delete(bw.conns, a)
					// Keep the state of this sc in bw.connSt until its state becomes Shutdown.
				}
			}
			bw.mu.Unlock()
			for _, a := range add {
				sc, err := bw.cc.NewSubConn([]resolver.Address{a}, balancer.NewSubConnOptions{})
				if err != nil {
					grpclog.Warningf("Error creating connection to %v. Err: %v", a, err)
				} else {
					bw.mu.Lock()
					bw.conns[a] = sc
					bw.connSt[sc] = &scState{
						addr: resAddrs[a],
						s:    connectivity.Idle,
					}
					bw.mu.Unlock()
					sc.Connect()//  这一步真正做了连接的操作。
				}
			}
			for _, c := range del {
				bw.cc.RemoveSubConn(c)
			}
		}
	}
}
```

## 1.35

### 基于 gRPC 的服务注册与发现和负载均衡的原理与实战

https://blog.csdn.net/ra681t58cjxsgckj31/article/details/110675344

### gRPC 流程

#### Dial 流程

- 调用 DialContext

  - `cc.parsedTarget = grpcutil.ParseTarget(cc.target, cc.dopts.copts.Dialer != nil)` 根据传入的 target 选择 resolver
  - 调用 getResolver，使用 parsedTarget 中的 scheme 去 clientConn 和注册过的 resolver 中查找 builder。

- `rWrapper, err := newCCResolverWrapper(cc, resolverBuilder)` 在这步使用 builder 的 build 方法构建 resolver

#### fileResolver 流程

- 创建 watcher 协程，并阻塞等待操作系统信号，或 context 关闭。
  - 接收到系统信号后，会读取并解析 `/etc/containerpilot/services.json` 文件中的活跃服务端节点列表。
  - 对比 resolver 中记录的活跃节点，查找出新节点和失效节点，调用 UpdateState 进行更新。
    - ResolverWrapper 中调用 updateResolverState
      - 首次进入 updateResolverState 方法会初始化 balanceWarpper，调用 maybeApplyDefaultServiceConfig 后调用 applyServiceConfigAndBalancer。
      - 调用 updateClientConnState

### resolver

当我们的服务刚刚成型时，可能一个服务只有一台实例，这时候 client 要建立 grpc 连接很简单，只需要指定 server 的 ip 就可以了。但是，当服务成熟了，业务量大了，这个时候，一个实例就就不够用了，我们需要部署一个服务集群。一个集群有很多实例，且可以随时的扩容，部分实例出现了故障也没关系，这样就提升了服务的处理能力和稳定性，但是也带来一个问题，grpc 的 client，如何和这个集群里的 server 建立连接？

这个问题可以一分为二，第一个问题：如何根据服务名称，返回实例的 ip？这个问题有很多种解决方案，我们可以使用一些成熟的服务发现组件，例如 consul 或者 zookeeper，也可以我们自己实现一个解析服务器；第二个问题，如何将我们选择的服务解析方式应用到 grpc 的连接建立中去？这个也不难，因为 grpc 的 resolver，就是帮我们解决这个问题的，本篇，我们就来探讨一下，grpc 的 resolver 是如何工作的，以及我们如何在项目中，使用 resolver 实现服务名称的解析。

#### resolver 的工作原理

关于 resolver，我们主要有两个问题：

- 程序启动时，客户端是如何从一个域名/服务名，获取到其对应的实例 ip，然后与之建立连接的呢？

- 运行过程中，如果后端的实例挂了，grpc 如何感知到，并重新建立连接呢？

接下来，我们就深入源码，搞清楚这两个问题。

#### 启动时的解析过程

我们在使用 grpc 的时候，首先要做的就是调用 Dial 或 DialContext 函数来初始化一个 clientConn 对象，而 resolver 是这个连接对象的一个重要的成员，所以我们首先看一看 clientConn 对象创建过程中，resolver 是怎么设置进去的。

客户端启动时，一定会调用 grpc 的 Dial 或 DialContext 函数来创建连接，而这两个函数都需要传入一个名为 target 的参数，target，就是连接的目标，也就是 server 了，接下来，我们就看一看，DialContext 函数里是如何处理这个 target 的。

首先，创建了一个 clientConn 对象，并把 target 赋给了对象中的 target：

```go
	cc := &ClientConn{
		target:            target,
		csMgr:             &connectivityStateManager{},
		conns:             make(map[*addrConn]struct{}),
		dopts:             defaultDialOptions(),
		blockingpicker:    newPickerWrapper(),
		czData:            new(channelzData),
		firstResolveEvent: grpcsync.NewEvent(),
	}
```

接下来，对这个 target 进行解析

```go
cc.parsedTarget = grpcutil.ParseTarget(cc.target)
```

我们可以看看 ParseTarget 这个函数做了些什么：

```go
// ParseTarget splits target into a resolver.Target struct containing scheme,
// authority and endpoint.
//
// If target is not a valid scheme://authority/endpoint, it returns {Endpoint:
// target}.
func ParseTarget(target string) (ret resolver.Target) {
	var ok bool
	ret.Scheme, ret.Endpoint, ok = split2(target, "://")
	if !ok {
		return resolver.Target{Endpoint: target}
	}
	ret.Authority, ret.Endpoint, ok = split2(ret.Endpoint, "/")
	if !ok {
		return resolver.Target{Endpoint: target}
	}
	return ret
}
```

可以看到，这个函数对 target 这个 string 进行了拆分，"://"前面的是 scheme，也就是解析方案，后面的又可以分为 authority 和 endpoint，endpoint 比较好理解，就是对端，也就是 server 的一个标识，authority 的话，我们的项目中并没有用，我也并不能完全理解，所以这里贴上[官方文档](https://github.com/grpc/grpc/blob/master/doc/naming.md)给出的一行解释，大家自行体会去吧。。

```go
authority indicates the DNS server to use, although this is only supported by some implementations. (In C-core, the default DNS resolver does not support this, but the c-ares based resolver supports specifying this in the form "IP:port".)
```

那么解析出来的 scheme 有什么用呢？不要急，我们回到 DialContext 函数，接着往下看：

解析完 target 之后执行的是下面这一句：

```go
resolverBuilder := cc.getResolver(cc.parsedTarget.Scheme)
```

也就是在根据解析的结果，包括 scheme 和 endpoint 这两个参数，获取一个 resolver 的 builder，我们来看看获取的逻辑是怎么样的：

```go
func (cc *ClientConn) getResolver(scheme string) resolver.Builder {
	for _, rb := range cc.dopts.resolvers {
		if scheme == rb.Scheme() {
			return rb
		}
	}
	return resolver.Get(scheme)
}
```

这里呢，其实就是在根据 scheme 进行查找，如果 resolver 已经在调用 DialContext 的时候通过 opts 参数传了进来，那我们就直接用，否则调用 resolver.Get(scheme)去找，我们项目中就是用的 resolver.Get(scheme)，所以我们再来看看这里是怎么做的：

```go
// Get returns the resolver builder registered with the given scheme.
//
// If no builder is register with the scheme, nil will be returned.
func Get(scheme string) Builder {
	if b, ok := m[scheme]; ok {
		return b
	}
	return nil
}
```

这里面，Get 函数是通过 m 这个 map，去查找有没有 scheme 对应的 resolver 的 builder，那么 m 这个 map 是什么时候插入的值呢？这个在 resolver 的 Register 函数里：

```go
func Register(b Builder) {
	m[b.Scheme()] = b
}
```

那么谁会去调用这个 Register 函数，向 map 中写入 resolver 呢？有两个人会去调，首先，grpc 实现了一个默认的解析器，也就是"passthrough"，这个看名字就理解了，就是透传，所谓透传就是，什么都不做，那么什么时候需要透传呢？当你调用 DialContext 的时候，如果传入的 target 本身就是一个 ip+port，这个时候，自然就不需要再解析什么了。那么"passthrough"对应的这个默认的解析器是什么时候注册到 m 这个 map 中的呢？这个调用在 passthrough 包的 init 函数里

```go
func init() {
	resolver.Register(&passthroughBuilder{})
}
```

而 grpc 包会 import 这个\_ "google.golang.org/grpc/internal/resolver/passthrough"包，所以，"passthrough"这个解析器在 grpc 初始化的时候就会被注册到 m 这个 map 中。

回到谁会去调用这个 Register 函数这个问题，事实上，服务名称的解析会根据我们项目使用的命名系统的不同，而存在多种不同的方案，如果我们是使用 consul 实现服务发现，那么我们就希望我们的解析器实现的是通过 concul 客户端获取服务信息，而如果我们用的是 dns 服务，那么我们的解析器就应该通过我们的 dns 服务器去获取指定域名对应的服务器 ip，总而言之，实现服务名称解析的方式太多了，所以 grpc 无法为我们一一实现，因此，需要我们自己根据自己使用的命名系统，去实现可以满足我们项目需求的 resolver，然后将其 Register 到 m 这个 map 中来，这个就涉及到 resolver 的具体用法了，我们下一节再详细讲，这里先记住，Register 这个函数，是需要我们自己实现完 resolver 去调用的。

再回到 DialContext 这个函数，在通过 getResolver 获取 resolver 的 builder 之后，如果结果为 nil，也就是没找到，会怎么样呢？

```go
	resolverBuilder := cc.getResolver(cc.parsedTarget.Scheme)
	if resolverBuilder == nil {
		// If resolver builder is still nil, the parsed target's scheme is
		// not registered. Fallback to default resolver and set Endpoint to
		// the original target.
		channelz.Infof(cc.channelzID, "scheme %q not registered, fallback to default scheme", cc.parsedTarget.Scheme)
		cc.parsedTarget = resolver.Target{
			Scheme:   resolver.GetDefaultScheme(),
			Endpoint: target,
		}
		resolverBuilder = cc.getResolver(cc.parsedTarget.Scheme)
		if resolverBuilder == nil {
			return nil, fmt.Errorf("could not get resolver for default scheme: %q", cc.parsedTarget.Scheme)
		}
	}
```

可以看到，scheme 会被设置为默认的 scheme，这个默认的 scheme 又是啥呢？

```go
defaultScheme = "passthrough"
```

是的，就是这个 passthrough，也就是说，没有获取到对应的 resolver 的时候，我们就认为是直接传了 ip+port 进来，就不去解析就好了。

接下来，DialContext 函数会使用获取到的 resolver 的 builder，构建一个 resolver，并将其赋给 cc 这个对象：

```go
    // Build the resolver.
	rWrapper, err := newCCResolverWrapper(cc, resolverBuilder)
	if err != nil {
		return nil, fmt.Errorf("failed to build resolver: %v", err)
	}
	cc.mu.Lock()
	cc.resolverWrapper = rWrapper
	cc.mu.Unlock()
```

而使用 builder 构建 resolver 的时候又做了什么呢？我们再来看看 newCCResolverWrapper 函数：

```go
// newCCResolverWrapper uses the resolver.Builder to build a Resolver and
// returns a ccResolverWrapper object which wraps the newly built resolver.
func newCCResolverWrapper(cc *ClientConn, rb resolver.Builder) (*ccResolverWrapper, error) {
	ccr := &ccResolverWrapper{
		cc:   cc,
		done: grpcsync.NewEvent(),
	}

	var credsClone credentials.TransportCredentials
	if creds := cc.dopts.copts.TransportCredentials; creds != nil {
		credsClone = creds.Clone()
	}
	rbo := resolver.BuildOptions{
		DisableServiceConfig: cc.dopts.disableServiceConfig,
		DialCreds:            credsClone,
		CredsBundle:          cc.dopts.copts.CredsBundle,
		Dialer:               cc.dopts.copts.Dialer,
	}

	var err error
	// We need to hold the lock here while we assign to the ccr.resolver field
	// to guard against a data race caused by the following code path,
	// rb.Build-->ccr.ReportError-->ccr.poll-->ccr.resolveNow, would end up
	// accessing ccr.resolver which is being assigned here.
	ccr.resolverMu.Lock()
	defer ccr.resolverMu.Unlock()
	ccr.resolver, err = rb.Build(cc.parsedTarget, ccr, rbo)
	if err != nil {
		return nil, err
	}
	return ccr, nil
}
```

这个函数最重要的一行，就是调用了我们传入的 builder 的 Build 方法，也就是这一行：

```go
ccr.resolver, err = rb.Build(cc.parsedTarget, ccr, rbo)
```

上面说过了，我们用的 resolver 还有 resolver 对应的 builder 都是需要我们自己实现的，所以 Build 方法里做了什么，这就要看你想让他做什么了，那么我们一般要在 Build 里完成哪些工作呢，这个我们下一节再探讨。

到这里，DialContext 函数中关于 resolver 的部分我们就看完了，也知道了 ClientConn 对象的 resolver 是如何设置进去的，但是 Dial 函数只是创建了一个抽象的连接，实际的 http2 连接并没有在这里创建，所以我们接下来要探讨的就是，实际创建 http2 连接的时候，是如何利用 resolver，获取到服务对应的 ip 的。

底层 http2 连接对应的是一个 grpc 的 stream，而 stream 的创建有两种方式，一种就是我们主动去创建一个 stream 池，这样当有请求需要发送时，我们可以直接使用我们创建好的 stream，关于 stream 池的用法，内容较多，本篇就先不探讨了，以后我会单独写一篇。除了我们自己创建，我们使用 protoc 为我们生成的客户端接口里，也会为我们实现 stream 的创建，也就是说这个完全是可以不用我们自己费心的，我们随便看一个 protoc 生成的客户端接口：

```go
func (c *greeterClient) SayHello(ctx context.Context, in *HelloRequest, opts ...grpc.CallOption) (*HelloReply, error) {
	out := new(HelloReply)
	err := c.cc.Invoke(ctx, "/helloworld.Greeter/SayHello", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}
```

这里，请求是通过 Invoke 函数发出的，所以接着看 Invoke：

```go
func (cc *ClientConn) Invoke(ctx context.Context, method string, args, reply interface{}, opts ...CallOption) error {
	// allow interceptor to see all applicable call options, which means those
	// configured as defaults from dial option as well as per-call options
	opts = combine(cc.dopts.callOptions, opts)

	if cc.dopts.unaryInt != nil {
		return cc.dopts.unaryInt(ctx, method, args, reply, cc, invoke, opts...)
	}
	return invoke(ctx, method, args, reply, cc, opts...)
}
```

在没有设置拦截器的情况下，会直接调 invoke：

```go
func invoke(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, opts ...CallOption) error {
	cs, err := newClientStream(ctx, unaryStreamDesc, cc, method, opts...)
	if err != nil {
		return err
	}
	if err := cs.SendMsg(req); err != nil {
		return err
	}
	return cs.RecvMsg(reply)
}
```

这里我们看到，发送请求之前，会先创建一个 stream，我们看看创建过程中的调用过程：

- newClientStream
- newAttemptLocked
- getTransport
- pick
- getReadyTransport
- connect
- resetTransport
- tryAllAddrs
- createTransport
- NewClientTransport
- newHTTP2Client

这个过程看着还是挺长的，所以没有逐一的去贴代码，注意到最后，调用了 newHTTP2Client，这就是我们想找的创建 http2 连接的地方了，再往底层我们就暂且不看了。

#### 运行过程中的更新过程

这一小节要搞明白的就是第二个问题：后端的实例挂了，client 如何感知，并创建新的连接呢？

这要从上一小节最后给到到创建 stream 的调用过程继续说起，注意到，调用过程中，有一个函数是 resetTransport，我们来看看这个函数的实现。

首先，这一段实现了连接的创建：

```go
newTr, addr, reconnect, err := ac.tryAllAddrs(addrs, connectDeadline)
		if err != nil {
			// After exhausting all addresses, the addrConn enters
			// TRANSIENT_FAILURE.
			ac.mu.Lock()
			if ac.state == connectivity.Shutdown {
				ac.mu.Unlock()
				return
			}
			ac.updateConnectivityState(connectivity.TransientFailure, err)

			// Backoff.
			b := ac.resetBackoff
			ac.mu.Unlock()

			timer := time.NewTimer(backoffFor)
			select {
			case <-timer.C:
				ac.mu.Lock()
				ac.backoffIdx++
				ac.mu.Unlock()
			case <-b:
				timer.Stop()
			case <-ac.ctx.Done():
				timer.Stop()
				return
			}
			continue
		}
```

这里调用的 tryAllAddrs 函数很好理解，就是把 resolver 解析结果中的 addr 全试一遍，知道和其中一个 addr 成功建立连接，如果失败，会等待一个退避时间，然后重试，需要注意的是，重试的时候，要经过 resetTransport 函数最开头的这段：

```go
if i > 0 {
			ac.cc.resolveNow(resolver.ResolveNowOptions{})
		}
```

也就是说，如果不是第一次创建连接，就要调用 clientConn 的 resolveNow 方法，重新获取一次解析的结果，这很重要，因为创建连接失败的原因很有可能就是上一次解析的结果对应的实例已经挂了。

上面说的是如果第一次连接就建立失败的情况，这种其实不太常见，常见的是连接建立之后，后端的服务因为网络故障或者升级之类的原因导致的连接断开，这种情况下 grpc 是如何发现的呢？要搞明白这个，就要看下 tryAllAddrs 函数里面调用的 createTransport 函数的内容了：

```go
onGoAway := func(r transport.GoAwayReason) {
		ac.mu.Lock()
		ac.adjustParams(r)
		once.Do(func() {
			if ac.state == connectivity.Ready {
				// Prevent this SubConn from being used for new RPCs by setting its
				// state to Connecting.
				//
				// TODO: this should be Idle when grpc-go properly supports it.
				ac.updateConnectivityState(connectivity.Connecting, nil)
			}
		})
		ac.mu.Unlock()
		reconnect.Fire()
	}

onClose := func() {
		ac.mu.Lock()
		once.Do(func() {
			if ac.state == connectivity.Ready {
				// Prevent this SubConn from being used for new RPCs by setting its
				// state to Connecting.
				//
				// TODO: this should be Idle when grpc-go properly supports it.
				ac.updateConnectivityState(connectivity.Connecting, nil)
			}
		})
		ac.mu.Unlock()
		close(onCloseCalled)
		reconnect.Fire()
	}
```

上面这两段，定义了连接 goAway 或者 close 的时候，该怎么处理，这两个函数会作为参数传入 transport.NewClientTransport 函数，进而设置到后面通过 newHTTP2Client 创建的 http2client 对象中，那么这两个函数何时会被触发呢？

以 onGoAway 函数为例，我们可以看看 http2client 的 reader 方法：

```go
func (t *http2Client) reader() {
	defer close(t.readerDone)
	// Check the validity of server preface.
	frame, err := t.framer.fr.ReadFrame()
	if err != nil {
		t.Close() // this kicks off resetTransport, so must be last before return
		return
	}
	t.conn.SetReadDeadline(time.Time{}) // reset deadline once we get the settings frame (we didn't time out, yay!)
	if t.keepaliveEnabled {
		atomic.StoreInt64(&t.lastRead, time.Now().UnixNano())
	}
	sf, ok := frame.(*http2.SettingsFrame)
	if !ok {
		t.Close() // this kicks off resetTransport, so must be last before return
		return
	}
	t.onPrefaceReceipt()
	t.handleSettings(sf, true)

	// loop to keep reading incoming messages on this transport.
	for {
		t.controlBuf.throttle()
		frame, err := t.framer.fr.ReadFrame()
		if t.keepaliveEnabled {
			atomic.StoreInt64(&t.lastRead, time.Now().UnixNano())
		}
		if err != nil {
			// Abort an active stream if the http2.Framer returns a
			// http2.StreamError. This can happen only if the server's response
			// is malformed http2.
			if se, ok := err.(http2.StreamError); ok {
				t.mu.Lock()
				s := t.activeStreams[se.StreamID]
				t.mu.Unlock()
				if s != nil {
					// use error detail to provide better err message
					code := http2ErrConvTab[se.Code]
					msg := t.framer.fr.ErrorDetail().Error()
					t.closeStream(s, status.Error(code, msg), true, http2.ErrCodeProtocol, status.New(code, msg), nil, false)
				}
				continue
			} else {
				// Transport error.
				t.Close()
				return
			}
		}
		switch frame := frame.(type) {
		case *http2.MetaHeadersFrame:
			t.operateHeaders(frame)
		case *http2.DataFrame:
			t.handleData(frame)
		case *http2.RSTStreamFrame:
			t.handleRSTStream(frame)
		case *http2.SettingsFrame:
			t.handleSettings(frame, false)
		case *http2.PingFrame:
			t.handlePing(frame)
		case *http2.GoAwayFrame:
			t.handleGoAway(frame)
		case *http2.WindowUpdateFrame:
			t.handleWindowUpdate(frame)
		default:
			errorf("transport: http2Client.reader got unhandled frame type %v.", frame)
		}
	}
}
```

可以看到，reader 方法会读取连接上的所有消息，如果是 GoAway 类型，则会调用上面我们设置的 onGoAway，而 onGoAway 函数里的 reconnect.Fire()，会触发 reconnect 这个事件，这个事件被触发会怎么样呢？我们再回到 resetTransport 函数，这个函数在连接成功创建之后，会阻塞在这里：

```go
// Block until the created transport is down. And when this happens,
		// we restart from the top of the addr list.
		<-reconnect.Done()
```

也就是说，函数在等这个连接 goAway 或者 close，当这两种情况发生时，程序就会接着走，也就是进入下一次循环，就会重新获取 resolver 的结果，然后建立连接，这样就说通了，我们再来捋一下：

- 首先，已经连接的后端发生了故障；
- 然后，已经建立的 http2client 读到了连接 goAway；
- 再然后，resetTransport 进入一次新的循环，重新获取解析结果；
- 最后，resetTransport 里通过新获取到的地址，重新建立连接

到这里，我们就搞清楚了，grpc 是如何保证连接一直是可用的了。

#### resolver 的使用

明白了大致原理，我们再来看看如何使用，其实最关键的一点在上面已经说过了，就是我们自己实现满足我们自己业务要求的 resolver，这里我就系统的举一个例子吧。

假设，我们后端的每一个服务都对应了一个域名，比如订单服务是 service.order，支付服务是 service.payment，然后我们自己的域名解析系统提供一个 web api，url 是http://myself.dns.xyz，当你想获取订单服务对应的实例的ip+port时，只需要发送一条：

GET http://myself.dns.xyz?service=service.order

欧克，接下来我们来实现这个解析器。

首先，我们创建一个单独的包，就叫 mydns 吧，注意在这个包里，我们要实现两个东西，一个是 resolver，一个是 resolver 的 builder

我们先来实现 resolver：

```go
type mydnsResolver struct {
	domain       string
	port         string
	address      map[resolver.Address]struct{}
	ctx    context.Context
	cancel context.CancelFunc
	cc     resolver.ClientConn
	wg sync.WaitGroup
}

// ResolveNow resolves immediately
func (mr *mydnsResolver) ResolveNow(resolver.ResolveNowOptions) {
	select {
	case mr.rn <- struct{}{}:
	default:
	}
}

// Close stops resolving
func (mr *mydnsResolver) Close() {
	mr.cancel()
	mr.wg.Wait()
}

func (mr *mydnsResolver) watcher() {
	defer util.CheckPanic()
	defer mr.wg.Done()

	for {
		select {
		case <-mr.ctx.Done():
			return
		case <-mr.rn:
		}
		result, err := mr.resolveByHttpDNS()
		if err != nil || len(result) == 0 {
			continue
		}
		mr.cc.UpdateState(resolver.State{Addresses: result})
	}
}

func (mr *mydnsResolver) resolveByHttpDNS() ([]resolver.Address, error) {
	var items []string = make([]string, 0, 4)

	//这里实现通过向http://myself.dns.xyz发送get请求获取实例ip列表，并存入items中

	var addresses = make([]resolver.Address, 0, len(items))
	for _, v := range items {
		addr := net.JoinHostPort(v, mr.port)
		a := resolver.Address{
			Addr:       addr,
			ServerName: addr, // same as addr
			Type:       resolver.Backend,
		}
		addresses = append(addresses, a)
	}

	return addresses, nil
}
```

再来实现 builder：

```go
type mydnsBuilder struct {
}

func NewBuilder() resolver.Builder {
	return &mydnsBuilder{}
}

// Scheme for mydns
func (mb *mydnsBuilder) Scheme() string {
	return "mydns"
}

// Build
func (mb *mydnsBuilder) Build(target resolver.Target, cc resolver.ClientConn, _ resolver.BuildOptions) (resolver.Resolver, error) {
	host, port, err := net.SplitHostPort(target.Endpoint)
	if err != nil {
		host = target.Endpoint
		port = "80"
	}

	ctx, cancel := context.WithCancel(context.Background())
	mr := &mydnsResolver{
		domain:       host,
		port:         port,
		cc:           cc,
		rn:           make(chan struct{}, 1),
		address:      make(map[resolver.Address]struct{}),
	}
	mr.ctx, pr.cancel = ctx, cancel

	mr.wg.Add(1)
	go mr.watcher()

	mr.ResolveNow(resolver.ResolveNowOptions{})
	return mr, nil
}
```

接下来我们还要实现，当这个包初始化时，将 scheme 注册到 grpc 的解析器 map 中：

```go
func init() {
	resolver.Register(NewBuilder())
}
```

实现好这个包之后，我们只需要在调用 Dial 的文件 import mydns 这个包，并且保证传入的 target 满足以下格式：

```go
mydns://service.order
```

grpc 就会使用我们实现的解析器，向我们自己的 dns 服务器请求服务对应的 ip 地址了，就是这么简单～

Reference:[grpc 进阶篇之 resolver](https://blog.csdn.net/u013536232/article/details/108556544)

[grpc 进阶篇之 retry 拦截器](https://blog.csdn.net/u013536232/article/details/108308504)

### golang grpc keepalive

最近遇到 grpc 客户端报错 `rpc error: code = Unavailable desc = transport is closing`，原因是连接长时间没有使用，被服务端断开，这种情况通过简单粗暴的重试策略可以解决，更加优雅的解决方案是增加保持连接策略

服务端

```go
var kaep = keepalive.EnforcementPolicy{
    MinTime:             5 * time.Second, // If a client pings more than once every 5 seconds, terminate the connection
    PermitWithoutStream: true,            // Allow pings even when there are no active streams
}

var kasp = keepalive.ServerParameters{
    MaxConnectionIdle:     15 * time.Second, // If a client is idle for 15 seconds, send a GOAWAY
    MaxConnectionAge:      30 * time.Second, // If any connection is alive for more than 30 seconds, send a GOAWAY
    MaxConnectionAgeGrace: 5 * time.Second,  // Allow 5 seconds for pending RPCs to complete before forcibly closing connections
    Time:                  5 * time.Second,  // Ping the client if it is idle for 5 seconds to ensure the connection is still active
    Timeout:               1 * time.Second,  // Wait 1 second for the ping ack before assuming the connection is dead
}

server := grpc.NewServer(grpc.KeepaliveEnforcementPolicy(kaep), grpc.KeepaliveParams(kasp))
```

客户端

```go
var kacp = keepalive.ClientParameters{
    Time:                10 * time.Second, // send pings every 10 seconds if there is no activity
    Timeout:             time.Second,      // wait 1 second for ping ack before considering the connection dead
    PermitWithoutStream: true,             // send pings even without active streams
}

conn, err := grpc.Dial(*addr, grpc.WithInsecure(), grpc.WithKeepaliveParams(kacp))
```

[Are these WithKeepaliveParams supposed to cause a connection shutdown / affect streams](https://github.com/grpc/grpc-go/issues/3837)

## grpc-go 源码解析 6-keepalive

https://erpeng.github.io/2019/08/15/grpc-go-keepalive/

## grpc 名称发现与负载均衡

https://manguijie.top/2018/09/grpc-name-resolve-loadbalance

## Keepalive

https://zhuanlan.zhihu.com/p/261047524
https://my.oschina.net/u/4325773/blog/3339284
https://segmentfault.com/a/1190000021133249
https://studygolang.com/articles/25004
https://github.com/grpc/grpc-go/issues/3837
