---
date: 2023-06-09
tag: 
  - golang
---

# å­—å…¸ï¼ˆgo1.20ï¼‰

Todo

```go
// mapaccess1 returns a pointer to h[key].  Never returns nil, instead
// it will return a reference to the zero object for the elem type if
// the key is not in the map.
// NOTE: The returned pointer may keep the whole map live, so don't
// hold onto it for very long.
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
```

t.hashMightPanic() 

```todo
è¯·æ•™ä¸‹ï¼Œmapæ‰©å®¹æ˜¯åœ¨å†™å…¥æˆ–è€…åˆ é™¤çš„æ—¶å€™æ‰æ‹·è´æ•°æ®çš„ï¼Œé‚£ä¼šä¸ä¼šæœ‰ä¸€ç§æƒ…å†µï¼ŒæŸä¸ªbucketä¸€ç›´æ²¡å†™å…¥ï¼Œä½†æ˜¯åˆè§¦å‘äº†ç¬¬äºŒæ¬¡æ‰©å®¹ï¼Œè¿™ç§æƒ…å†µä¼šæ€æ ·

è§¦å‘ç¬¬äºŒæ¬¡æ‰©å®¹å°±æ˜¯ä¸€ç‰‡æ–°çš„åŒºåŸŸï¼Œä¸ç†è§£ä¼šæœ‰ä»€ä¹ˆé—®é¢˜

æŸä¸ªoldbucketé‡Œçš„æ•°æ®æ²¡æœ‰è¿ç§»

åº”è¯¥æ˜¯ä¸ä¼šå‡ºç°è¿™ç§æƒ…å†µçš„ã€‚

å°±æ¯”å¦‚å†™å…¥mapassignå‡½æ•°æ¥è¯´ï¼Œåœ¨å†™å…¥å‰ä¼šæœ‰åˆ¤æ–­mapæ˜¯å¦åœ¨æ‰©å®¹çš„çŠ¶æ€ï¼Œå› æ­¤æ¯è°ƒç”¨ä¸€æ¬¡growWorkå‡½æ•°å°±ä¼šæœ‰ä¸€ä¸ªoldbucketæ¬è¿å®Œæˆã€‚

if h.growing() {
    growWork(t, h, bucket)
}
func growWork(t *maptype, h *hmap, bucket uintptr) {
	// æ¬è¿å°è¯•å†™å…¥çš„é‚£ä¸ªbucket
	evacuate(t, h, bucket&h.oldbucketmask())
	if h.growing() {
		// æ¬è¿ç¬¬ä¸€ä¸ªæœªæ¬è¿çš„bucket
		evacuate(t, h, h.nevacuate)
	}
}

å†çœ‹è§¦å‘æ¡ä»¶æœ‰ä¸¤ç§æƒ…å†µï¼š

å…ƒç´ æ•°é‡>6.5*2^Bï¼Œå¯¹äºè¿™ä¸ªæƒ…å†µï¼Œæˆ‘ä»¬å‡è®¾æ¯æ¬¡çš„å†™å…¥æ“ä½œéƒ½è½å…¥å‰2^B-1ä¸ªbucketä¸­ï¼Œå³æœ€åä¸€ä¸ªbucketä¸€ç›´ä¸è¢«å†™å…¥ï¼Œé‚£ä¹ˆå½“ä½ å†™å…¥2^Bä¸ªæ–°å…ƒç´ æ—¶ï¼Œå°±ä¸€å®šä¼šè§¦å‘åˆ°æœ€åä¸€ä¸ªæœ€åä¸€ä¸ªbucketï¼Œè¿™æ—¶æ•´ä¸ªoldbucketéƒ½æ‰©å®¹å®Œæˆäº†ï¼Œæ­¤æ—¶å…ƒç´ æ•°é‡ä¸ºâ€‹2*2^B < 6.5*2^Bï¼Œå¹¶ä¸ä¼šè§¦å‘äºŒæ¬¡æ‰©å®¹
æº¢å‡ºæ¡¶è¿‡å¤šï¼Œå¯¹äºè¿™ä¸ªæƒ…å†µï¼Œæˆ‘ä»¬å‡è®¾æ¯æ¬¡çš„å†™å…¥æ“ä½œéƒ½è½å…¥ä¸€ä¸ªbucketä¸Šï¼Œè€Œä¸€ä¸ªbucketä¸­æœ‰8ä¸ªcellï¼Œå› æ­¤æ‰©å®¹çš„è¿›åº¦è‚¯å®šæ˜¯å¤§äºoverflowbucketæº¢å‡ºæ¡¶çš„å¢é•¿é€Ÿåº¦çš„ã€‚
ç»¼ä¸Šæ‰€è¿°ï¼Œåœ¨æ‰©å®¹çš„çŠ¶æ€ä¸‹ï¼ŒæŒç»­çš„å¯¹mapè¿›è¡Œå†™å…¥æˆ–è€…åˆ é™¤æ“ä½œï¼Œéƒ½ä¼šåœ¨åˆ°è¾¾ç¬¬äºŒæ¬¡æ‰©å®¹æ¡ä»¶å‰å°±å®Œæˆäº†æ‰©å®¹çš„æ•´ä¸ªæ¬è¿è¿‡ç¨‹ã€‚

å¹¶ä¸”mapassignå‡½æ•°ä¸­ï¼Œå†™äº†åªæœ‰åœ¨éæ‰©å®¹çŠ¶æ€ä¸‹ï¼Œå¹¶ä¸”è¾¾åˆ°ä¸¤ä¸ªæ‰©å®¹æ¡ä»¶ä¹‹ä¸€ï¼Œæ‰ä¼šæœ‰æ–°çš„æ‰©å®¹hashGrowã€‚

if !h.growing() && (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {
    hashGrow(t, h)
    goto again // Growing the table invalidates everything, so try again
}
```

- map åªæœ‰åœ¨å†™å…¥æ—¶æ‰ä¼šå‘ç”Ÿæ‰©å®¹å’Œè¿ç§»ï¼Œå¹¶ä¸”åœ¨å®Œå…¨è¿ç§»åæ‰ä¼š gc é‡Šæ”¾æ—§æ¡¶çš„å†…å­˜ã€‚å¦‚æœ map å†™å…¥ä¸é¢‘ç¹ï¼Œæ˜¯å¦å°±ä¼šè®© map åœ¨ä¸€æ®µæ—¶é—´å†…å§‹ç»ˆå ç”¨äº†ä¸¤å€å†…å­˜å‘¢ï¼Ÿ

å¯¹äºæµ·é‡å°å¯¹è±¡ï¼Œåº”ç›´æ¥ç”¨å­—å…¸å­˜å‚¨é”®å€¼æ•°æ®æ‹·è´ï¼Œè€ŒéæŒ‡é’ˆã€‚è¿™æœ‰åŠ©äºå‡å°‘éœ€è¦æ‰«æçš„å¯¹è±¡æ•°é‡ï¼Œç¼©çŸ­åƒåœ¾å›æ”¶æ—¶é—´ã€‚å­—å…¸ä¸ä¼šæ”¶ç¼©å†…å­˜ï¼Œé€‚å½“æ›¿æ¢æ–°å¯¹è±¡æ˜¯æœ‰å¿…è¦çš„ã€‚

ç»“æ„ï¼š

```go
var (
  // Possible tophash values. We reserve a few possibilities for special marks.
	// Each bucket (including its overflow buckets, if any) will have either all or none of its
	// entries in the evacuated* states (except during the evacuate() method, which only happens
	// during map writes and thus no one else can observe the map during that time).
	emptyRest      = 0 // this cell is empty, and there are no more non-empty cells at higher indexes or overflows.
	emptyOne       = 1 // this cell is empty
	evacuatedX     = 2 // key/elem is valid.  Entry has been evacuated to first half of larger table.
	evacuatedY     = 3 // same as above, but evacuated to second half of larger table.
	evacuatedEmpty = 4 // cell is empty, bucket is evacuated.
	minTopHash     = 5 // minimum tophash for a normal filled cell.

  // flags
	iterator     = 1 // there may be an iterator using buckets
	oldIterator  = 2 // there may be an iterator using oldbuckets
	hashWriting  = 4 // a goroutine is writing to the map
	sameSizeGrow = 8 // the current map growth is to a new map of the same size
)


// A header for a Go map.
type hmap struct {
	// Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go.
	// Make sure this stays in sync with the compiler's definition.
	count     int // # live cells == size of map.  Must be first (used by len() builtin)
	flags     uint8
	B         uint8  // log_2 of # of buckets (can hold up to loadFactor * 2^B items)
	noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details
	hash0     uint32 // hash seed

	buckets    unsafe.Pointer // array of 2^B Buckets. may be nil if count==0.
	oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing
	nevacuate  uintptr        // progress counter for evacuation (buckets less than this have been evacuated)

	extra *mapextra // optional fields
}
// mapextra holds fields that are not present on all maps.
type mapextra struct {
	// If both key and elem do not contain pointers and are inline, then we mark bucket
	// type as containing no pointers. This avoids scanning such maps.
	// However, bmap.overflow is a pointer. In order to keep overflow buckets
	// alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow.
	// overflow and oldoverflow are only used if key and elem do not contain pointers.
	// overflow contains overflow buckets for hmap.buckets.
	// oldoverflow contains overflow buckets for hmap.oldbuckets.
	// The indirection allows to store a pointer to the slice in hiter.
	overflow    *[]*bmap
	oldoverflow *[]*bmap

	// nextOverflow holds a pointer to a free overflow bucket.
	nextOverflow *bmap
}

// A bucket for a Go map.
type bmap struct {
	// tophash generally contains the top byte of the hash value
	// for each key in this bucket. If tophash[0] < minTopHash,
	// tophash[0] is a bucket evacuation state instead.
	tophash [bucketCnt]uint8
	// Followed by bucketCnt keys and then bucketCnt elems.
	// NOTE: packing all the keys together and then all the elems together makes the
	// code a bit more complicated than alternating key/elem/key/elem/... but it allows
	// us to eliminate padding which would be needed for, e.g., map[int64]int8.
	// Followed by an overflow pointer.
}
```

åˆå§‹åŒ–ï¼š

- å­—é¢é‡åˆ›å»ºæ—¶çš„å¤„ç† [maplit](https://github.com/golang/go/blob/release-branch.go1.20/src/cmd/compile/internal/walk/complit.go#L417)

  å½¢å¦‚ä»¥ä¸‹æ–¹å¼åˆ›å»º map ä¼šåœ¨ç¼–è¯‘æœŸä¼˜åŒ–
  ```go
	hash := map[string]int{
		"1": 2,
		"3": 4,
		"5": 6,
	}
	```

	å¦‚æœ map ä¸­çš„å…ƒç´ [å°äº 25 ä¸ª](https://github.com/golang/go/blob/release-branch.go1.20/src/cmd/compile/internal/walk/complit.go#L503)æ—¶ï¼Œä¼šå°†ä¸Šè¿°ä»£ç [è½¬æ¢](https://github.com/golang/go/blob/release-branch.go1.20/src/cmd/compile/internal/walk/complit.go#L507)æˆä»¥ä¸‹å½¢å¼ï¼š

	```go
	hash := make(map[string]int, 3)
	hash["1"] = 2
	hash["3"] = 4
	hash["5"] = 6
	```

	å¦‚æœ map ä¸­çš„å…ƒç´ [è¶…è¿‡ 25 ä¸ª](https://github.com/golang/go/blob/release-branch.go1.20/src/cmd/compile/internal/walk/complit.go#L436)æ—¶ï¼Œä¼šå°†ä»£ç è½¬æ¢æˆä»¥ä¸‹å½¢å¼ï¼š

	```go
	hash := make(map[string]int, 26)
	vstatk := []string{"1", "2", "3", ... ï¼Œ "26"}
	vstatv := []int{1, 2, 3, ... , 26}
	for i := 0; i < len(vstak); i++ {
			hash[vstatk[i]] = vstatv[i]
	}
	```

	`vstatk` å’Œ `vstatv` ä¼šè¢«ç¼–è¾‘å™¨ç»§ç»­å±•å¼€ã€‚

- è¿è¡Œæ—¶çš„å¤„ç† [makemap](https://github.com/golang/go/blob/release-branch.go1.20/src/runtime/map.go#L304)
  - é¦–å…ˆæ ¹æ® hit è®¡ç®—å‡ºï¼ˆå®¹é‡ï¼Ÿï¼Ÿï¼Ÿä¸æ¡¶å…ƒç´ å¤§å°çš„ä¹˜ç§¯ï¼‰ map éœ€è¦ç”³è¯·çš„å†…å­˜å¤§å°ï¼Œæ£€æµ‹å†…å­˜æ˜¯å¦æº¢å‡ºæˆ–ç”³è¯·çš„å†…å­˜è¶…è¿‡é™åˆ¶ // TODO hit æ˜¯å¦æ˜¯ cap
  - åˆå§‹åŒ– h å¹¶å¼•å…¥éšæœºç§å­
  - é»˜è®¤æ¡¶å®¹é‡ä¸º 1ï¼Œå…ƒç´ éœ€è¦è¶…è¿‡ä¸€ä¸ªæ¡¶å®¹é‡ï¼ˆ8ï¼‰æ—¶è®¡ç®— map çš„è£…è½½å› å­ï¼ˆå…ƒç´ æ•°é‡ / æ¡¶æ•°é‡ï¼‰ï¼Œè¶…è¿‡ 6.5 åˆ™å°†æ¡¶å®¹é‡ç¿»å€

	```go
	const (
		// Maximum number of key/elem pairs a bucket can hold.
		bucketCntBits = 3
		bucketCnt     = 1 << bucketCntBits
		// Maximum average load of a bucket that triggers growth is 6.5.
		// Represent as loadFactorNum/loadFactorDen, to allow integer math.
		loadFactorNum = 13
		loadFactorDen = 2
	)
	func overLoadFactor(count int, B uint8) bool {
		return count > bucketCnt && uintptr(count) > loadFactorNum*(bucketShift(B)/loadFactorDen)
	}
	```

  - å¦‚æœ map çš„æ¡¶æ•°é‡è¶…è¿‡ 1 æ—¶ï¼Œä¼šåœ¨ makemap ä¸­ç«‹å³åˆ†é…å†…å­˜ï¼Œå¦åˆ™å°†åœ¨ mapassign ä¸­åˆ†é…
  - é€šè¿‡ `makeBucketArray` åˆ†é…å†…å­˜ï¼š
  
	```go
	// makeBucketArray initializes a backing array for map buckets.
	// 1<<b is the minimum number of buckets to allocate.
	// dirtyalloc should either be nil or a bucket array previously
	// allocated by makeBucketArray with the same t and b parameters.
	// If dirtyalloc is nil a new backing array will be alloced and
	// otherwise dirtyalloc will be cleared and reused as backing array.
	func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) {
		base := bucketShift(b)
		nbuckets := base
		// For small b, overflow buckets are unlikely.
		// Avoid the overhead of the calculation.
		if b >= 4 {
			// Add on the estimated number of overflow buckets
			// required to insert the median number of elements
			// used with this value of b.
			nbuckets += bucketShift(b - 4)
			sz := t.bucket.size * nbuckets
			up := roundupsize(sz)
			if up != sz {
				nbuckets = up / t.bucket.size
			}
		}

		if dirtyalloc == nil {
			buckets = newarray(t.bucket, int(nbuckets))
		} else {
			// dirtyalloc was previously generated by
			// the above newarray(t.bucket, int(nbuckets))
			// but may not be empty.
			buckets = dirtyalloc
			size := t.bucket.size * nbuckets
			if t.bucket.ptrdata != 0 {
				memclrHasPointers(buckets, size)
			} else {
				memclrNoHeapPointers(buckets, size)
			}
		}

		if base != nbuckets {
			// We preallocated some overflow buckets.
			// To keep the overhead of tracking these overflow buckets to a minimum,
			// we use the convention that if a preallocated overflow bucket's overflow
			// pointer is nil, then there are more available by bumping the pointer.
			// We need a safe non-nil pointer for the last overflow bucket; just use buckets.
			nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize)))
			last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize)))
			last.setoverflow(t, (*bmap)(buckets))
		}
		return buckets, nextOverflow
	}
	```
    
		- å¦‚æœæ¡¶çš„æ•°é‡è¶…è¿‡ $2^4$ï¼Œä¼š[å¢åŠ ä¸€äº›é¢å¤– $2ğµâˆ’4$ ä¸ªæº¢å‡ºæ¡¶](https://github.com/golang/go/blob/release-branch.go1.20/src/runtime/map.go#L345)
		- é€šè¿‡ [newarray](https://github.com/golang/go/blob/release-branch.go1.20/src/runtime/malloc.go#L1268) åˆ›å»ºæ¡¶æ•°ç»„
		- å¦‚æœç”³è¯·çš„åŒæ•°é‡è¶…è¿‡åŸºç¡€æ•°é‡ï¼ˆå³è¶…è¿‡äº† $2^4$ ä¸ªæ¡¶ï¼‰ï¼Œæ­¤æ—¶ä¼šå°† hmap ä¸­çš„ nextOverflow æŒ‡é’ˆæŒ‡å‘é¢å¤–åˆ›å»ºæº¢å‡ºæ¡¶çš„ç¬¬ä¸€ä¸ªï¼Œå°†æœ€åä¸€ä¸ªæº¢å‡ºæ¡¶çš„æº¢å‡ºæŒ‡é’ˆä½è®¾ç½®æˆ hmap çš„ç¬¬ä¸€ä¸ªæ¡¶ã€‚è¿™æ ·åšå¯ä»¥é¿å…è·Ÿè¸ªæº¢å‡ºæ¡¶çš„å¼€é”€ï¼Œå½“ nextOverflow çš„æº¢å‡ºæ¡¶æŒ‡é’ˆä¸º nilï¼Œåˆ™å¯ä»¥ç»§ç»­åç§»æŒ‡é’ˆæ¥è¿½åŠ æº¢å‡ºæ¡¶ï¼Œå¦åˆ™è¯´æ˜æº¢å‡ºæ¡¶å·²ç»ä½¿ç”¨å®Œæ¯•

		::: tips 
		ä» makeclear ä¸­è°ƒç”¨ makeBucketArray ä¼šä¼  dirtyalloc å‚æ•°ï¼Œæ­¤æ—¶åœ¨ makeBucketArray ä¸­ä¼šä½¿ç”¨è¯¥ç‰‡å·²ç”³è¯·å¥½çš„å†…å­˜ï¼Œå¹¶åˆå§‹åŒ–
		:::

  - æ­¤æ—¶æ¡¶å†…å­˜å·²ç»åˆ†é…å®Œæˆï¼Œå°†æ¡¶çš„åœ°å€è®¾ç½®åˆ° hmap ä¸Šï¼Œå¦‚æœåœ¨ `makeBucketArray` ä¸­ç”Ÿæˆæº¢å‡ºæ¡¶ï¼Œåˆ™åˆå§‹åŒ– hmap çš„ extra å­—æ®µï¼Œå¹¶è®¾ç½® nextOverflow

```go
func maplit(n *Node, m *Node, init *Nodes) {
	a := nod(OMAKE, nil, nil)
	a.Esc = n.Esc
	a.List.Set2(typenod(n.Type), nodintconst(int64(n.List.Len())))
	litas(m, a, init)

	entries := n.List.Slice()
	if len(entries) > 25 {
		...
		return
	}

	// Build list of var[c] = expr.
	// Use temporaries so that mapassign1 can have addressable key, elem.
	...
}
// makemap implements Go map creation for make(map[k]v, hint).
// If the compiler has determined that the map or the first bucket
// can be created on the stack, h and/or bucket may be non-nil.
// If h != nil, the map can be created directly in h.
// If h.buckets != nil, bucket pointed to can be used as the first bucket.
func makemap(t *maptype, hint int, h *hmap) *hmap {
	mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)
	if overflow || mem > maxAlloc {
		hint = 0
	}

	// initialize Hmap
	if h == nil {
		h = new(hmap)
	}
	h.hash0 = fastrand()

	// Find the size parameter B which will hold the requested # of elements.
	// For hint < 0 overLoadFactor returns false since hint < bucketCnt.
	B := uint8(0)
	for overLoadFactor(hint, B) {
		B++
	}
	h.B = B

	// allocate initial hash table
	// if B == 0, the buckets field is allocated lazily later (in mapassign)
	// If hint is large zeroing this memory could take a while.
	if h.B != 0 {
		var nextOverflow *bmap
		h.buckets, nextOverflow = makeBucketArray(t, h.B, nil)
		if nextOverflow != nil {
			h.extra = new(mapextra)
			h.extra.nextOverflow = nextOverflow
		}
	}

	return h
}
```

è®¿é—®ï¼šè®¡ç®— key çš„ hash å€¼ï¼Œé€šè¿‡å’Œ B ä½ä¸è®¡ç®—å‡ºæ‰€åœ¨æ¡¶ï¼Œéå†æ¡¶ä¸­çš„å…ƒç´ ï¼Œå¦‚æœæœ‰æº¢å‡ºæ¡¶ï¼Œéå†æº¢å‡ºæ¡¶

- for range çš„æ–¹å¼
- é€šè¿‡ `_ = hash[key]` çš„æ–¹å¼ï¼š
  - ç¼–è¯‘é˜¶æ®µå°†è¯æ³•ã€è¯­æ³•åˆ†æå™¨ç”Ÿæˆçš„æŠ½è±¡è¯­æ³•æ ‘ä¸­ op ä¸º OINDEXMAP çš„èŠ‚ç‚¹ï¼ˆå½¢å¦‚ `X[Index] (index of map)`ï¼‰ä½œè½¬æ¢ï¼Œå¦‚æœæ˜¯èµ‹å€¼è¯­å¥ï¼Œåˆ™ä¼šè½¬æ¢æˆ mapassign æ–¹æ³•ï¼Œå¦‚æœéèµ‹å€¼è¯­å¥ï¼Œå¦åˆ™ä¼šè½¬æ¢æˆ mapaccess1ï¼š
  - mapaccess1 è®¿é—®å…ƒç´ æ—¶é¦–å…ˆæ£€æµ‹ h.flags çš„å†™å…¥ä½ï¼Œå¦‚æœæœ‰åç¨‹å†™å…¥æ—¶ç›´æ¥ç»ˆæ­¢ç¨‹åº
  - // TODO å’Œ mapaccess2 ç±»ä¼¼ 
- é€šè¿‡ `_, _ = hash[key]` çš„æ–¹å¼ï¼š
  - ç¼–è¯‘é˜¶æ®µå°†è¯æ³•ã€è¯­æ³•åˆ†æå™¨ç”Ÿæˆçš„æŠ½è±¡è¯­æ³•æ ‘ä¸­ op ä¸º OAS2MAPR çš„èŠ‚ç‚¹ï¼ˆå½¢å¦‚ `a, b = m[i]`ï¼‰è½¬æ¢æˆ mapaccess2ï¼š

	
	```go
	a,b = m[i]
	```

	```go
	var,b = mapaccess2*(t, m, i)
	a = *var
	```

	- mapaccess2 è®¿é—®å…ƒç´ æ—¶é¦–å…ˆæ£€æµ‹ h.flags çš„å†™å…¥ä½ï¼Œå¦‚æœæœ‰åç¨‹å†™å…¥æ—¶ç›´æ¥ç»ˆæ­¢ç¨‹åº
	- è®¡ç®— key çš„ hashï¼Œå¹¶è®¡ç®—å‡º key æ‰€åœ¨çš„æ­£å¸¸æ¡¶ç¼–å·ï¼Œé¢å¤–æ£€æŸ¥ map çš„æ—§æ¡¶æ˜¯å¦ä¸ºç©º
  	- å¦‚æœ map æ—§æ¡¶éç©ºï¼Œåˆ™å®šä½åˆ°å½“å‰ key å¯¹åº”çš„æ—§æ¡¶ä½ï¼Œæ£€æŸ¥æ—§æ¡¶ä½æ˜¯å¦è¿ç§»ï¼Œå¦‚æœæœªè¿ç§»åˆ™ä»è€æ¡¶ä¸­è·å–æ•°æ®

		```go
		const (
			// Possible tophash values. We reserve a few possibilities for special marks.
			// Each bucket (including its overflow buckets, if any) will have either all or none of its
			// entries in the evacuated* states (except during the evacuate() method, which only happens
			// during map writes and thus no one else can observe the map during that time).
			emptyRest      = 0 // this cell is empty, and there are no more non-empty cells at higher indexes or overflows.
			emptyOne       = 1 // this cell is empty
			evacuatedX     = 2 // key/elem is valid.  Entry has been evacuated to first half of larger table.
			evacuatedY     = 3 // same as above, but evacuated to second half of larger table.
			evacuatedEmpty = 4 // cell is empty, bucket is evacuated.
			minTopHash     = 5 // minimum tophash for a normal filled cell.
		)
		func evacuated(b *bmap) bool {
			// è¿ç§»ä»¥æ¡¶ä½å•ä½ï¼Œæ‰€ä»¥è·å–ç¬¬ä¸€ä¸ªå•å…ƒå³å¯çŸ¥é“è¯¥æ¡¶æ˜¯å¦è¿ç§»å®Œæˆ
			h := b.tophash[0]
			// åˆ¤æ–­æ¡¶ tophash ç¬¬ä¸€ä½çš„å€¼æ˜¯å¦æ˜¯ evacuatedXã€evacuatedYã€evacuatedEmpty è¿™ä¸‰ç§çŠ¶æ€æ˜¯æ¡¶è¿ç§»å®Œåè®¾ç½®çš„çŠ¶æ€
			return h > emptyOne && h < minTopHash
		}
		```

  	- éå†å®šä½åˆ°æ¡¶çš„æ¯ä¸ªå•å…ƒï¼Œå¦‚æœ tophash ä¸ä¸€è‡´ä¸” tophash çš„å€¼ä¸º emptyReset åˆ™è¯´æ˜æ¡¶ä¸­æ— è¯¥ keyï¼Œéå†æ¡¶çš„æº¢å‡ºæ¡¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ç»§ç»­åˆ¤æ–­
  	- å¦‚æœ tophash ä¸€è‡´ï¼Œåˆ™å¯¹æ¯”å•å…ƒä¸­å…ƒç´ çš„ key å’Œæ‰€éœ€çš„ key æ˜¯å¦ä¸€è‡´ï¼Œå¦‚æœä¸€è‡´åˆ™è¿”å›å…ƒç´ çš„åœ°å€ï¼Œå¦åˆ™è¿”å› zeroVal

	::: tips
	mapaccess1/2 å¦‚æœ key ä¸å­˜åœ¨ï¼Œä¸ä¼šè¿”å› nilï¼Œä¼šè¿”å›ä¸€ä¸ªå…ƒç´ ç±»å‹é›¶å€¼çš„æŒ‡é’ˆ
	:::

```go
// walkIndexMap walks an OINDEXMAP node.
// It replaces m[k] with *map{access1,assign}(maptype, m, &k)
func walkIndexMap(n *ir.IndexExpr, init *ir.Nodes) ir.Node {
	n.X = walkExpr(n.X, init)
	n.Index = walkExpr(n.Index, init)
	map_ := n.X
	t := map_.Type()
	fast := mapfast(t)
	key := mapKeyArg(fast, n, n.Index, n.Assigned)
	args := []ir.Node{reflectdata.IndexMapRType(base.Pos, n), map_, key}

	var mapFn ir.Node
	switch {
	case n.Assigned:
		mapFn = mapfn(mapassign[fast], t, false)
	case t.Elem().Size() > zeroValSize:
		args = append(args, reflectdata.ZeroAddr(t.Elem().Size()))
		mapFn = mapfn("mapaccess1_fat", t, true)
	default:
		mapFn = mapfn(mapaccess1[fast], t, false)
	}
	call := mkcall1(mapFn, nil, init, args...)
	call.SetType(types.NewPtr(t.Elem()))
	call.MarkNonNil() // mapaccess1* and mapassign always return non-nil pointers.
	star := ir.NewStarExpr(base.Pos, call)
	star.SetType(t.Elem())
	star.SetTypecheck(1)
	return star
}

// mapaccess1 returns a pointer to h[key].  Never returns nil, instead
// it will return a reference to the zero object for the elem type if
// the key is not in the map.
// NOTE: The returned pointer may keep the whole map live, so don't
// hold onto it for very long.
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	if raceenabled && h != nil {
		callerpc := getcallerpc()
		pc := abi.FuncPCABIInternal(mapaccess1)
		racereadpc(unsafe.Pointer(h), callerpc, pc)
		raceReadObjectPC(t.key, key, callerpc, pc)
	}
	if msanenabled && h != nil {
		msanread(key, t.key.size)
	}
	if asanenabled && h != nil {
		asanread(key, t.key.size)
	}
	if h == nil || h.count == 0 {
		if t.hashMightPanic() {
			t.hasher(key, 0) // see issue 23734
		}
		return unsafe.Pointer(&zeroVal[0])
	}
	if h.flags&hashWriting != 0 {
		fatal("concurrent map read and map write")
	}
	hash := t.hasher(key, uintptr(h.hash0))
	m := bucketMask(h.B)
	b := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))
	if c := h.oldbuckets; c != nil {
		if !h.sameSizeGrow() {
			// There used to be half as many buckets; mask down one more power of two.
			m >>= 1
		}
		oldb := (*bmap)(add(c, (hash&m)*uintptr(t.bucketsize)))
		if !evacuated(oldb) {
			b = oldb
		}
	}
	top := tophash(hash)
bucketloop:
	for ; b != nil; b = b.overflow(t) {
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
				if b.tophash[i] == emptyRest {
					break bucketloop
				}
				continue
			}
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			if t.indirectkey() {
				k = *((*unsafe.Pointer)(k))
			}
			if t.key.equal(key, k) {
				e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))
				if t.indirectelem() {
					e = *((*unsafe.Pointer)(e))
				}
				return e
			}
		}
	}
	return unsafe.Pointer(&zeroVal[0])
}
```

```go
func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) {
	if raceenabled && h != nil {
		callerpc := getcallerpc()
		pc := abi.FuncPCABIInternal(mapaccess2)
		racereadpc(unsafe.Pointer(h), callerpc, pc)
		raceReadObjectPC(t.key, key, callerpc, pc)
	}
	if msanenabled && h != nil {
		msanread(key, t.key.size)
	}
	if asanenabled && h != nil {
		asanread(key, t.key.size)
	}
	if h == nil || h.count == 0 {
		if t.hashMightPanic() {
			t.hasher(key, 0) // see issue 23734
		}
		return unsafe.Pointer(&zeroVal[0]), false
	}
	if h.flags&hashWriting != 0 {
		fatal("concurrent map read and map write")
	}
	hash := t.hasher(key, uintptr(h.hash0))
	m := bucketMask(h.B)
	b := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))
	if c := h.oldbuckets; c != nil {
		if !h.sameSizeGrow() {
			// There used to be half as many buckets; mask down one more power of two.
			m >>= 1
		}
		oldb := (*bmap)(add(c, (hash&m)*uintptr(t.bucketsize)))
		if !evacuated(oldb) {
			b = oldb
		}
	}
	top := tophash(hash)
bucketloop:
	for ; b != nil; b = b.overflow(t) {
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
				if b.tophash[i] == emptyRest {
					break bucketloop
				}
				continue
			}
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			if t.indirectkey() {
				k = *((*unsafe.Pointer)(k))
			}
			if t.key.equal(key, k) {
				e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))
				if t.indirectelem() {
					e = *((*unsafe.Pointer)(e))
				}
				return e, true
			}
		}
	}
	return unsafe.Pointer(&zeroVal[0]), false
}
```

åˆ é™¤ï¼š

- æ£€æŸ¥ map æ˜¯å¦åœ¨å†™å…¥ï¼Œæœ‰å†™å…¥ä¼šç›´æ¥ç»ˆæ­¢ç¨‹åº
- é€šè¿‡ç§å­å’Œ key é€šè¿‡å¯¹åº”çš„ç±»å‹çš„ hash å‡½æ•°è®¡ç®—å‡º hash å€¼ï¼Œå¹¶æ›´æ–° flags æ ‡è®° map æ­£åœ¨å†™å…¥
- å°† hash å’Œ `1<<b-1` æ‰§è¡Œä¸æ“ä½œæ¥è·å¾— bucket æ¡¶å·
  - å¦‚æœ map æ­£åœ¨æ‰§è¡Œæ‰©å®¹ï¼Œåˆ™å¯¹è¯¥ bucket æ‰§è¡Œä¸€æ¬¡æ‰©å®¹è¿ç§»
- å°† bucket åºå·å’Œæ¯ä¸ª bucket çš„ size ç›¸ä¹˜çš„ç»“æœä» map æ¡¶èµ·å§‹åœ°å€åšåç§»ï¼Œè·å¾— bucket åºå·æ¡¶çš„åœ°å€
- è·å– hash çš„é«˜å…«ä½å€¼ topï¼Œå¦‚æœ top å°äº minTopHashï¼Œåˆ™ top+= minTopHash
- é¦–å…ˆéå†è¯¥æ¡¶ï¼Œå¦‚æœè¯¥æ¡¶æœ‰æº¢å‡ºæ¡¶ï¼Œåˆ™æŒç»­éå†æº¢å‡ºæ¡¶ï¼›å¯¹äºæ¯ä¸ªæ¡¶ï¼Œéå†å…¶ä¸­çš„å…«ä¸ªå•å…ƒ
  - å¦‚æœå½“å‰å•å…ƒçš„ tophash å€¼å’Œ å¾…æŸ¥ key çš„ tophash ä¸ä¸€è‡´
    - å¦‚æœå½“å‰å•å…ƒä¸º emptyRestï¼Œè¡¨æ˜åç»­éƒ½æœªç©ºï¼Œåˆ™åœæ­¢å¯¹æ­¤æ¡¶çš„ç»§ç»­æœç´¢
    - å¦‚æœå½“å‰å•å…ƒä¸ä¸º emptyRestï¼Œç»§ç»­æŸ¥è¯¢åç»­å•å…ƒ
  - å½“æŸ¥æ‰¾åˆ° tophash ä¸€è‡´çš„å•å…ƒï¼Œä¼šé€šè¿‡ `add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))` ä»æ¡¶èµ·å§‹åœ°å€åç§» tophash æ•°ç»„å’ŒæœªåŒ¹é…çš„ keySize æ¥è·å¾—å½“å‰å•å…ƒå¯¹åº”çš„ key åœ°å€ï¼Œå¦‚æœ key å­˜çš„æ˜¯é—´å€ï¼Œè¿˜ä¼šç»§ç»­è·å–å¯¹åº”çš„åœ°å€
  - åˆ¤æ–­è¯¥å•å…ƒ key çš„å€¼å’Œæ‰€éœ€åˆ é™¤çš„ key æ˜¯å¦ä¸€è‡´ï¼Œä¸ä¸€è‡´åˆ™ç»§ç»­éå†ä¸‹ä¸€ä¸ªå•å…ƒ
    - æŸ¥æ‰¾åˆ°ä¸€è‡´çš„å•å…ƒåä¼šå°†è¯¥å•å…ƒçš„ tophash è®¾ç½®æˆ emptyOneï¼Œæ¥ä¸‹æ¥ä¼šæ‰§è¡Œä¸€æ®µé€»è¾‘å¤„ç† emptyReset
      - å¦‚æœå½“å‰å•å…ƒæ˜¯è¯¥æ¡¶çš„æœ€åä¸€ä¸ªå…ƒç´ ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æº¢å‡ºæ¡¶ï¼Œå¦‚æœæœ‰åˆ™æ£€æŸ¥æº¢å‡ºæ¡¶çš„é¦–ä¸ªå•å…ƒçš„ tophash ä¸æ˜¯ emptyReset åˆ™æ‰§è¡Œ notLast é€»è¾‘
      - å¦‚æœå½“å‰å•å…ƒä¸æ˜¯è¯¥æ¡¶çš„æœ€åä¸€ä¸ªå…ƒç´ ï¼Œä¸”å½“å‰å•å…ƒåä¸€å•å…ƒçš„ tophash ä¸æ˜¯ emptyReset åˆ™æ‰§è¡Œ notLast é€»è¾‘
      - notLast é€»è¾‘ï¼šå¦‚æœæº¢å‡ºæ¡¶é¦–ä¸ªå•å…ƒçš„ tophash ä¸æ˜¯ emptyReset åˆ™å°† map çš„ count æ•°å‡ä¸€ï¼Œå¦‚æœå½“å‰ map å·²æ— å…ƒç´ ï¼ˆå³ count ä¸º 0ï¼‰ï¼Œåˆ™é‡ç½® map çš„ hash0ï¼ˆç§å­ï¼‰
      - å¦‚æœå½“å‰å•å…ƒæ˜¯æ¡¶çš„æœ€åä¸€ä¸ªå•å…ƒï¼Œåˆ™æ‰§è¡Œè®¾ç½® emptyReset çš„é€»è¾‘ï¼ˆLast é€»è¾‘ï¼‰
        - ä»å½“å‰å•å…ƒå‘ä½ä½å¾ªç¯è®¾ç½® tophash ä¸º emptyResetï¼Œå¦‚æœå¾ªç¯ä½ä¸æ˜¯ 0ï¼ˆéæ¡¶èµ·å§‹ä½ï¼‰ï¼Œåˆ™åˆ¤æ–­è¯¥ä½æ˜¯å¦æ˜¯ emptyOneï¼Œå¦‚æœæ˜¯åˆ™ç»§ç»­æ›´æ–°ä¸º emptyResetï¼Œå¦åˆ™è·³å‡ºå¾ªç¯
        - å¦‚æœéå†ä½ä¸ºæ¡¶çš„èµ·å§‹ä½ï¼Œåˆ¤æ–­å½“å‰éå†çš„æ¡¶æ˜¯å¦æ˜¯åˆ é™¤å…ƒç´ çš„æ‰€åœ¨æ¡¶ï¼ˆéæº¢å‡ºæ¡¶ï¼‰ï¼Œå¦‚æœæ˜¯ï¼Œè¯´æ˜åˆ é™¤å…ƒç´ çš„æ‰€åœ¨æ¡¶ï¼ˆä»åŸå§‹æ¡¶è‡³è¯¥æ¡¶çš„æº¢å‡ºæ¡¶ï¼‰å·²å…¨éƒ¨å¤„ç†å®Œæˆï¼Œè·³å‡ºå¾ªç¯
        - è·å–åˆ é™¤å…ƒç´ æ‰€åœ¨æ¡¶ï¼ˆå¯èƒ½ä¸ºæº¢å‡ºæ¡¶ï¼‰çš„å‰ä¸€ä¸ªæ¡¶ï¼ˆå¯èƒ½ä¸ºåŸå§‹æ¡¶ä¹Ÿå¯èƒ½ä¸ºæº¢å‡ºæ¡¶ï¼‰ï¼Œç»§ç»­ä»ç¬¬å…«ä½å¼€å§‹å¾ªç¯è®¾ç½® tophash
- æ£€æŸ¥å½“å‰ map flags çš„ hashWriting æ˜¯å¦è¢«å–åï¼Œæ˜¯åˆ™è¯´æ˜æœ‰å…¶ä»–åç¨‹æ­£åœ¨å†™å…¥ï¼Œç›´æ¥ç»ˆæ­¢ç¨‹åºï¼Œå¦åˆ™æ¸…é™¤å†™å…¥ä½

```go
func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {
	if h.flags&hashWriting != 0 {
		fatal("concurrent map writes")
	}

	hash := t.hasher(key, uintptr(h.hash0))

	// Set hashWriting after calling t.hasher, since t.hasher may panic,
	// in which case we have not actually done a write (delete).
	h.flags ^= hashWriting

	bucket := hash & bucketMask(h.B)
	if h.growing() {
		growWork(t, h, bucket)
	}
	b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))
	bOrig := b
	top := tophash(hash)
search:
	for ; b != nil; b = b.overflow(t) {
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
				if b.tophash[i] == emptyRest {
					break search
				}
				continue
			}
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			k2 := k
			if t.indirectkey() {
				k2 = *((*unsafe.Pointer)(k2))
			}
			if !t.key.equal(key, k2) {
				continue
			}
			// Only clear key if there are pointers in it.
			if t.indirectkey() {
				*(*unsafe.Pointer)(k) = nil
			} else if t.key.ptrdata != 0 {
				memclrHasPointers(k, t.key.size)
			}
			e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))
			if t.indirectelem() {
				*(*unsafe.Pointer)(e) = nil
			} else if t.elem.ptrdata != 0 {
				memclrHasPointers(e, t.elem.size)
			} else {
				memclrNoHeapPointers(e, t.elem.size)
			}
			b.tophash[i] = emptyOne
			// If the bucket now ends in a bunch of emptyOne states,
			// change those to emptyRest states.
			// It would be nice to make this a separate function, but
			// for loops are not currently inlineable.
			if i == bucketCnt-1 {
				if b.overflow(t) != nil && b.overflow(t).tophash[0] != emptyRest {
					goto notLast
				}
			} else {
				if b.tophash[i+1] != emptyRest {
					goto notLast
				}
			}
			for {
				b.tophash[i] = emptyRest
				if i == 0 {
					if b == bOrig {
						break // beginning of initial bucket, we're done.
					}
					// Find previous bucket, continue at its last entry.
					c := b
					for b = bOrig; b.overflow(t) != c; b = b.overflow(t) {
					}
					i = bucketCnt - 1
				} else {
					i--
				}
				if b.tophash[i] != emptyOne {
					break
				}
			}
		notLast:
			h.count--
			// Reset the hash seed to make it more difficult for attackers to
			// repeatedly trigger hash collisions. See issue 25237.
			if h.count == 0 {
				h.hash0 = fastrand()
			}
			break search
		}
	}

	if h.flags&hashWriting == 0 {
		fatal("concurrent map writes")
	}
	h.flags &^= hashWriting
}

// bucketMask returns 1<<b - 1, optimized for code generation.
func bucketMask(b uint8) uintptr {
	return bucketShift(b) - 1
}

// noldbuckets calculates the number of buckets prior to the current map growth.
func (h *hmap) noldbuckets() uintptr {
	oldB := h.B
	if !h.sameSizeGrow() {
		oldB--
	}
	return bucketShift(oldB)
}

// tophash calculates the tophash value for hash.
func tophash(hash uintptr) uint8 {
	top := uint8(hash >> (goarch.PtrSize*8 - 8))
	if top < minTopHash {
		top += minTopHash
	}
	return top
}

func (b *bmap) overflow(t *maptype) *bmap {
	return *(**bmap)(add(unsafe.Pointer(b), uintptr(t.bucketsize)-goarch.PtrSize))
}
```

hasGrowth

```go
func hashGrow(t *maptype, h *hmap) {
	// If we've hit the load factor, get bigger.
	// Otherwise, there are too many overflow buckets,
	// so keep the same number of buckets and "grow" laterally.
	bigger := uint8(1)
	if !overLoadFactor(h.count+1, h.B) {
		bigger = 0
		h.flags |= sameSizeGrow
	}
	oldbuckets := h.buckets
	newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)

	flags := h.flags &^ (iterator | oldIterator)
	if h.flags&iterator != 0 {
		flags |= oldIterator
	}
	// commit the grow (atomic wrt gc)
	h.B += bigger
	h.flags = flags
	h.oldbuckets = oldbuckets
	h.buckets = newbuckets
	h.nevacuate = 0
	h.noverflow = 0

	if h.extra != nil && h.extra.overflow != nil {
		// Promote current overflow buckets to the old generation.
		if h.extra.oldoverflow != nil {
			throw("oldoverflow is not nil")
		}
		h.extra.oldoverflow = h.extra.overflow
		h.extra.overflow = nil
	}
	if nextOverflow != nil {
		if h.extra == nil {
			h.extra = new(mapextra)
		}
		h.extra.nextOverflow = nextOverflow
	}

	// the actual copying of the hash table data is done incrementally
	// by growWork() and evacuate().
}
```

å†™å…¥ï¼šxxxx

åœ¨ #è®¿é—® ä¸­

```go

```

::: tips
// Like mapaccess, but allocates a slot for the key if it is not present in the map.
:::

- ä¿®æ”¹
- æ‰©å®¹
  - ç­‰é‡æ‰©å®¹
  - ç¿»å€æ‰©å®¹

- [map å®è·µä»¥åŠå®ç°åŸç†](https://blog.csdn.net/u010853261/article/details/99699350)
- [å“ˆå¸Œè¡¨](https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap)
- [map ç¼©å®¹](https://eddycjy.com/posts/go/map-reset/)
